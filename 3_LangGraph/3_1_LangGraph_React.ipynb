{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78dcd886",
   "metadata": {},
   "source": [
    "# This code is to setup a React Agent Using LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c5d4ff",
   "metadata": {},
   "source": [
    "This code has the following features: \n",
    "- It accepts input / question from the user \n",
    "- Determine if this contain information about a given Topic (US Related Data)\n",
    "- IF the question does contain topic related to US, then it should use the knowledgebase stored within Chroma DB (Vector Store) to answer the question. \n",
    "- If the topic of the question is not related to US, then it should be answered using LLM\n",
    "- LLM Used is Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae7087",
   "metadata": {},
   "source": [
    "![title](First_Agent.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e295e8",
   "metadata": {},
   "source": [
    "## Importing required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f49ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import operator\n",
    "from typing import List\n",
    "from pydantic import BaseModel , Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph,END\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain_community.vectorstores import Chroma \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fefb3c",
   "metadata": {},
   "source": [
    "## Load the user data and create a VectorDB and Retriver Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef42ead",
   "metadata": {},
   "source": [
    "There the focus is: \n",
    "- Read the input context file (text)\n",
    "- Load them onto a Vector DB (Chroma)\n",
    "- Build a Retriver Object \n",
    "- Also build a function to collect all the document (retrived) into a unified document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5cd2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the embedding model \n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "#Creating Embedding object\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76675294",
   "metadata": {},
   "source": [
    "- BAAI/bge-small-en: Its a Sentence embedding  model by Beijing Academy of AI \n",
    "- Embedding size : 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4465cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 447.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#Read the input file onto loader object (Directory Loader + Text loader)\n",
    "loader = DirectoryLoader(\"../data\", glob=\"./*.txt\", loader_cls=TextLoader, show_progress=True)\n",
    "\n",
    "#Perform Load operation\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25019a",
   "metadata": {},
   "source": [
    "Here we used DirectoryLoader to read the text file within the directory. Key arguments in DirectoryLoader are \n",
    "- Path : Path to the directory \n",
    "- glob : What files that we want to read (default all files)\n",
    "- glob : In out case we are only interested in .txt files, therefore \"./.txt\" where ./ indicate current directory. \n",
    "- loader_cls : Specify the loader to be used to read the selected objects within the directory  \n",
    "- Snow_Progress: TO see the data loading progress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8da3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the document into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200, \n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "#Perform Splitting operation \n",
    "new_docs = text_splitter.split_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb6e41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input is split into 56 chunks \n",
    "len(new_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7e6665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating DB Instance (Chroma)\n",
    "db = Chroma.from_documents(new_docs, embeddings)\n",
    "\n",
    "#Creating a retriver object\n",
    "retriver = db.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c81c3e",
   "metadata": {},
   "source": [
    "- Retriver object is created from Chroma (Vector DB)\n",
    "- search_kwargs = 3 : We will be getting top 3 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2d56943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to collect the text from the document retrived from retriver so that \n",
    "def format_docs(docs):\n",
    "    return \"\\n \\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede851d4",
   "metadata": {},
   "source": [
    "- Function is responsible for reading the document retrived by the **retriver** object \n",
    "- Consolidate them into a single textual document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329b5664",
   "metadata": {},
   "source": [
    "## Building Nodes and Edges based on the solution diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03380488",
   "metadata": {},
   "source": [
    "### Function 1 : Supervisor Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3128ef2",
   "metadata": {},
   "source": [
    "- Supervisor Node is responsible to receive the user input. \n",
    "- Determine what is the associated **Topic** from the user input \n",
    "- Perform necessary steps so that Router can decide which route to take : **LLM Route** or **RAG Route**\n",
    "- We use an LLM to make the appropriate decision of the topic here. \n",
    "- Therefore need to define a **Pydantic** class to define a data model that we expect LLM to return."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32608cf9",
   "metadata": {},
   "source": [
    "Before we jump into Supervisor Nodes we need to Define 2 core components \n",
    "1. Pydantic Function\n",
    "2. AgentStates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed87e4b",
   "metadata": {},
   "source": [
    "#### PyDantic Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d58a7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Pydantic library\n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "#Defining the Pydantic class \n",
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic : str = Field(description=\"Identified Topic from user input\")\n",
    "    Reasoning : str = Field(description= \"Rationale or Reason for selecting the topic from the user input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fec14cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attaching the Pydantic Class to Parser output \n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "parser = PydanticOutputParser(pydantic_object=TopicSelectionParser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb96221",
   "metadata": {},
   "source": [
    "- In the first step we have created a class inherited from **BaseModel** to define the data model that we want to enforce in the output of LLM. \n",
    "- While defining the model, we also explained the **Fields** (Topic & Resoning) that we expect from LLM output and  What is expected to be included in those fields, explained by **Field Description**. \n",
    "- Therefore so far we have only created the **Data Model** \n",
    "- Next we need an enforcer. Something that can take the Data Model defined and then enforce or ask LLM to follow the structure defined. \n",
    "- This is where **PydanticOutputParser** comes in. \n",
    "- **PydanticOutputParser** here act as **Translator** and **Structurer** : It is responsible to read the output of LLM and ensure that it enforces the data model defined (by Pydantic)\n",
    "-- The blueprint in Pydantic Class tell the Parser what kind of data that you expect and what piece of the output data you should be called under the fields  (Topic and Reasoning )\n",
    "-- The description help the parser and the LLM to understand what information to extract for each of the field. \n",
    "-- Eg of Raw Text : \"The user wants to talk about 'AI ethics' because they mentioned 'fairness in algorithms'.\"\n",
    "-- Topic: AI Ethics \n",
    "-- Reasoning : Fairness in algorithms \n",
    "- Among all output Parsers available **PydanticOutputParser** is used here to ensure the Reliability, Robustness and better Error Handling. \n",
    "- Other Output Parsers are: \n",
    "-- StrOutputParser : Simplest of the Parser and it returns the string output from LLM \n",
    "-- JsonOutputParser : This parser is good in getting JSON output. \n",
    "-- Specialised Parsers : CommaSeparatedListOutputParser, DatetimeOutputParser, XMLOutputParser etc. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641da342",
   "metadata": {},
   "source": [
    "#### Agent States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b7944f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Agent State\n",
    "class AgentState(TypedDict): \n",
    "    messages : Annotated[Sequence[BaseMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b5e693",
   "metadata": {},
   "source": [
    "- AgentState act as a NoteBook that the Agent uses to keep track of all the converstions / discussions history. \n",
    "- AgentState is of type TypedDict. This is a dictionary structure object that enforces specific  **Keys** and **Values**\n",
    "- In the class we are defining AgentState to be of type **TypedDict**, therefore this class object will have specific keys and values (Defined Template with **slots** or placeholders for capturing the information). \n",
    "- *messages* in this case is the placeholder to capture the information in this case historical conversations. \n",
    "-- Sequence[BaseMessage] : The message placeholder contain **sequence**  of BaseMessage objects. \n",
    "-- **BaseMessage** indicate an entry of conversation (User Question, AI Message etc)\n",
    "-- operator.add : This implies that we cannot replace and old item in this list, instead we can only **append** the new messages to the end of the existing list.\n",
    "- In simple terms, AgentState is a special type of data container (like a structured dictionary) specifically designed to hold a sequence of conversational messages. The operator.add part tells the system that when you update this AgentState, new messages should always be added to the end of the existing conversation history, preserving the flow of the conversation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1356a9a",
   "metadata": {},
   "source": [
    "#### Model to be used by LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d690231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model \n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48e2454",
   "metadata": {},
   "source": [
    "-  Gemini model will be used by the model to infer the user question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633727f2",
   "metadata": {},
   "source": [
    "#### Function 1 : Supervisor Functional Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fd49fc",
   "metadata": {},
   "source": [
    "- Function will take the user input \n",
    "- Identify the topic based on the structure defined in the prompt \n",
    "- Generate output ie Selected Topic and Reasoning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24df7233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the function (Supervisor) \n",
    "\n",
    "def function_1(state: AgentState):\n",
    "    \n",
    "    #Identify the node that executes the task \n",
    "    print(\"------> Supervisor <-----------\")\n",
    "    \n",
    "    #Capturing the user question \n",
    "    #Taking the last message as the recent user question \n",
    "    question = state[\"messages\"][-1] \n",
    "    \n",
    "    #Display the question \n",
    "    print(\"Question is : \", question)\n",
    "    \n",
    "    #Next is to define the input to the LLM. \n",
    "    template = \"\"\" \n",
    "    Your task is to clarify if the given user query into the following categories : [USA, Not Related].\n",
    "    Only respond with the Category Name and Nothing else. \n",
    "    \n",
    "    User question : {question}\n",
    "    \n",
    "    {format_instructions}\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    #Creating Prompt for LLM \n",
    "    prompt = PromptTemplate(\n",
    "        template=template, \n",
    "        input_variables=[\"question\"],\n",
    "        partial_variables={\"format_instructions\":parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    #Creating the chain \n",
    "    chain = prompt | model | parser \n",
    "    \n",
    "    #Executing the Chain \n",
    "    response = chain.invoke({\"question : \", question })\n",
    "    \n",
    "    #Display the response \n",
    "    print(\"Parsed response from Supervisor : \", response)\n",
    "    \n",
    "    #Returning state \n",
    "    return{\"messages\" : [response.Topic]}  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb5815",
   "metadata": {},
   "source": [
    "### Function 2 : RAG "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a07154",
   "metadata": {},
   "source": [
    "- Function will take the user input \n",
    "- Check in the vector DB for relevant answers \n",
    "- Produce output based on the context captured within the vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30e8b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAG Function : Function 2 \n",
    "def function_2(state: AgentState):\n",
    "    \n",
    "    #Identify the node that performs the execution \n",
    "    print(\"============> RAG Node <======================\")\n",
    "    \n",
    "    #Identifying the user question as the fist message\n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    #Defining the Prompt to execute \n",
    "    prompt = PromptTemplate(\n",
    "        \n",
    "        #Defining a RAG Template\n",
    "        template= \"\"\" \n",
    "        You are an assistant for answering the given question and provide accurate answers. \n",
    "        Use the following pieces retrieved from the context to answer the question. \n",
    "        If you dont know the answer, then you just say that you dont know the answer. \n",
    "        Use a maximum of three sentences to answer the question.\n",
    "        \n",
    "        \\n \n",
    "        Question : {question} \n",
    "        \n",
    "        \\n\n",
    "        Context : {context}\n",
    "        \n",
    "        \\n\n",
    "        Answer : \n",
    "        \"\"\" ,\n",
    "        input_variables=['context', 'question']\n",
    "    )\n",
    "    \n",
    "    #Building the RAG Chain \n",
    "    rag_chain = (\n",
    "        {\"context\": retriver | format_docs, \"question\": RunnablePassthrough()}\n",
    "        |   prompt \n",
    "        |   model \n",
    "        |   StrOutputParser()     \n",
    "    )\n",
    "\n",
    "    #Generating Result \n",
    "    result = rag_chain.invoke(question)\n",
    "\n",
    "    #Return message\n",
    "    return {\"messages\": [result]}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3a38c",
   "metadata": {},
   "source": [
    "#### LLM Call : Function 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189c8a3",
   "metadata": {},
   "source": [
    "- In this function we use the input from the user \n",
    "- Generate output from LLM based on user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff70f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM Call \n",
    "def function_3(state: AgentState):\n",
    "    \n",
    "    #Identifying the node that is executing \n",
    "    print(\"===========> LLM Call <=====================\")\n",
    "    \n",
    "    #Getting the user question \n",
    "    question = state[\"messages\"][0]\n",
    "    \n",
    "    #User question is passed onto the model to get the response \n",
    "    complete_query = \"Answer the following question with your knowledge of the reason world. The question is  \" + question \n",
    "    \n",
    "    #Generating LLM Response \n",
    "    response = model.invoke(complete_query)\n",
    "    \n",
    "    #Result from LLM \n",
    "    return{\"messages\": [response.content]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3d3fc5",
   "metadata": {},
   "source": [
    "#### Building a Router "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f324392",
   "metadata": {},
   "source": [
    "- **Router** is responsible to pass the control to RAG or LLM based on the type of Topic. \n",
    "- If the user topic to determined by **Supervisor** to determine if we need to use RAG Path or LLM Path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "103d1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we define the router function \n",
    "def router(state: AgentState):\n",
    "    \n",
    "    #Identifying the node we are in \n",
    "    print(\"====================> Router <================\")\n",
    "    \n",
    "    #Fetching the last message (output from Supervisor )\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    #Display the last message \n",
    "    print(\"Messaged received to Router \", last_message)\n",
    "    \n",
    "    #Establishing the Routing Rules \n",
    "    if \"usa\" in last_message.lower(): \n",
    "        return \"RAG Call\"\n",
    "    else: \n",
    "        return \"LLM Call\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cbfb4f",
   "metadata": {},
   "source": [
    "## Building Workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcf4d3",
   "metadata": {},
   "source": [
    "- Here we build orchestration framework for the workflow.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "697c4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will be building the Orchestration workflow \n",
    "#Importing the required libraries \n",
    "from langgraph.graph import StateGraph, END \n",
    "\n",
    "#Creating the StateGrapth object aka workflow \n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "#Adding Nodes \n",
    "workflow.add_node(\"Supervisor\", function_1) #Naming Function 1 as Node Supervisor \n",
    "workflow.add_node(\"RAG\", function_2) #Naming Function 2 as Node RAG \n",
    "workflow.add_node(\"LLM\", function_3) #Naming Function 3 as Node LLM \n",
    "\n",
    "#Specifying the beginning node (to which input will go to)\n",
    "workflow.set_entry_point(\"Supervisor\")\n",
    "\n",
    "#Defining the conditional Edges \n",
    "workflow.add_conditional_edges(\n",
    "    \"Supervisor\", #Intial Node to accept the input \n",
    "    router, #Supervisor output will go to router \n",
    "    {\n",
    "        \"RAG Call\" : \"RAG\", #Deligate to RAG \n",
    "        \"LLM Call\" : \"LLM\" #Deligate to LLM \n",
    "    }\n",
    ")\n",
    "\n",
    "#Adding Nodes Edge \n",
    "workflow.add_edge(\"RAG\", END)\n",
    "workflow.add_edge(\"LLM\", END)\n",
    "\n",
    "#Compile the workflow to create the app \n",
    "app=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9db3185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000002CA541ABE10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the workflow \n",
    "workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8480b229",
   "metadata": {},
   "source": [
    "#### Executing the workflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05b7b1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------> Supervisor <-----------\n",
      "Question is :  What is the Population of Singapore? \n",
      "Parsed response from Supervisor :  Topic='Not Related' Reasoning='The question is about the population of Singapore, which is not related to the USA.'\n",
      "====================> Router <================\n",
      "Messaged received to Router  Not Related\n",
      "===========> LLM Call <=====================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['What is the Population of Singapore? ',\n",
       "  'Not Related',\n",
       "  'The population of Singapore is not a static number and fluctuates.  However, according to the latest readily available data (which can vary slightly depending on the source and the exact date of the data collection), the population of Singapore is approximately **5.7 to 5.9 million people**.  To get the most precise current figure, you should consult official Singaporean government statistics websites.']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating input \n",
    "state={\"messages\":[\"What is the Population of Singapore? \"]}\n",
    "\n",
    "#Executing the app \n",
    "app.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f89997",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
