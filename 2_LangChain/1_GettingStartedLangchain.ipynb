{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the environment variable onto the code\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "#Loading the environment variable \n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the environment variables into local local environment for execution \n",
    "\n",
    "#Openai API Key load \n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#Langsmith Tracking and tracing \n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "\n",
    "\n",
    "#Groq API Key load \n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x00000201962841D0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000201962868D0> root_client=<openai.OpenAI object at 0x00000201962AFAD0> root_async_client=<openai.AsyncOpenAI object at 0x0000020196287550> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "#Invoking Openai Models \n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#Creating the model \n",
    "#llm=ChatOpenAI(model=\"o1-mini\", temperature=1)\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems designed to act as autonomous agents capable of making decisions, taking actions, and pursuing specific goals with minimal human intervention. The term \"agentic\" emphasizes the AI's capacity for agency—the ability to perceive its environment, reason about it, and execute actions to achieve desired outcomes.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Autonomy:** Agentic AI systems operate independently without requiring constant human oversight. They can initiate actions based on their programming and learned experiences.\n",
      "\n",
      "2. **Goal-Oriented Behavior:** These AI agents are designed to achieve specific objectives. They can set sub-goals, plan strategies, and adjust their actions based on feedback and changing circumstances.\n",
      "\n",
      "3. **Perception and Interaction:** Agentic AI can perceive its environment through sensors or data inputs and interact with it through actuators or output mechanisms. This allows them to navigate real-world or virtual environments effectively.\n",
      "\n",
      "4. **Learning and Adaptation:** Many agentic AI systems incorporate machine learning techniques, enabling them to improve their performance over time by learning from experiences and data.\n",
      "\n",
      "5. **Decision-Making:** They possess the ability to evaluate different options and make decisions based on predefined criteria, learned knowledge, or predictive models.\n",
      "\n",
      "### Examples of Agentic AI\n",
      "\n",
      "- **Autonomous Vehicles:** Self-driving cars navigate roads, make real-time decisions to avoid obstacles, and optimize routes without human input.\n",
      "  \n",
      "- **Virtual Assistants:** Advanced virtual assistants like Siri, Alexa, or Google Assistant perform tasks, manage schedules, and respond to user requests proactively.\n",
      "\n",
      "- **Robotics:** Service robots in industries like healthcare or manufacturing perform tasks such as surgery assistance, assembly line operations, or inventory management autonomously.\n",
      "  \n",
      "- **Intelligent Software Agents:** In finance, AI agents can execute trades based on market analysis, or in customer service, chatbots can handle inquiries and resolve issues without human intervention.\n",
      "\n",
      "### Applications of Agentic AI\n",
      "\n",
      "1. **Healthcare:** Autonomous diagnostic systems can analyze medical data and suggest treatments, while robotic surgeons perform precise operations.\n",
      "\n",
      "2. **Transportation:** Beyond self-driving cars, agentic AI can manage traffic systems, optimize logistics, and control drones for delivery services.\n",
      "\n",
      "3. **Finance:** AI agents can manage investment portfolios, detect fraudulent activities, and provide personalized financial advice.\n",
      "\n",
      "4. **Smart Homes and Cities:** Intelligent systems can control lighting, heating, security, and infrastructure management to create efficient living environments.\n",
      "\n",
      "5. **Entertainment:** AI-driven game characters and virtual environments that adapt to player behavior offer more immersive experiences.\n",
      "\n",
      "### Ethical and Practical Considerations\n",
      "\n",
      "While agentic AI offers numerous benefits, it also raises important ethical and practical issues:\n",
      "\n",
      "- **Accountability:** Determining responsibility for the actions of autonomous agents can be complex, especially in critical applications like healthcare or autonomous driving.\n",
      "\n",
      "- **Bias and Fairness:** AI agents trained on biased data may perpetuate or exacerbate existing biases, leading to unfair outcomes.\n",
      "\n",
      "- **Privacy:** Autonomous agents often require access to vast amounts of data, raising concerns about data privacy and security.\n",
      "\n",
      "- **Control and Safety:** Ensuring that agentic AI systems behave as intended and can be controlled or overridden when necessary is crucial to prevent unintended consequences.\n",
      "\n",
      "- **Job Displacement:** The automation of tasks by agentic AI may lead to job losses in certain sectors, necessitating strategies for workforce adaptation and retraining.\n",
      "\n",
      "### Future Prospects\n",
      "\n",
      "The development of agentic AI is advancing rapidly, driven by improvements in machine learning, sensor technologies, and computational power. Future trends may include:\n",
      "\n",
      "- **Enhanced Autonomy:** AI agents with higher levels of autonomy capable of handling more complex and dynamic environments.\n",
      "\n",
      "- **Collaboration Between AI and Humans:** Hybrid systems where agentic AI works alongside humans, augmenting human capabilities rather than replacing them.\n",
      "\n",
      "- **Ethical AI Frameworks:** Robust frameworks and regulations to guide the development and deployment of agentic AI, ensuring alignment with societal values and ethical standards.\n",
      "\n",
      "- **Interdisciplinary Research:** Combining insights from fields like cognitive science, robotics, and ethics to create more sophisticated and responsible agentic AI systems.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Agentic AI represents a significant advancement in artificial intelligence, enabling systems to operate with a degree of independence and purposefulness that can transform various aspects of society. While the potential benefits are substantial, it is essential to address the accompanying ethical, social, and technical challenges to ensure that agentic AI contributes positively to human progress.\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is agentic ai\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, so I need to figure out what ROBOGAAA is. The user is asking about it, so first, I'll start by recalling if I've heard of this term before. I might not be familiar with it off the top of my head, so I'll have to break it down. \n",
      "\n",
      "First, the name \"ROBOGAAA\" sounds like a combination of \"ROBO\" and \"GAAA.\" Maybe \"ROBO\" refers to a robot or robotics, and \"GAAA\" could be an acronym. Let me think, common acronyms like NASA or DARPA, but \"GAAA\" isn't a standard one. Alternatively, maybe it's a play on \"GOOG\" (like Google) but with a different ending. Wait, maybe it's a typo or a misspelling? Could it be \"ROBOGA\" or something else?\n",
      "\n",
      "Alternatively, could it be related to gaming? Sometimes games have names with creative spellings. Or perhaps it's a specific project or company. Let me try to think of any recent tech projects or startups. Maybe it's a new AI tool? I know there are lots of AI tools out there, like ChatGPT or MidJourney. \n",
      "\n",
      "Another angle: ROBOGAAA might be a portmanteau. \"Robogaaa\" could be combining robot with \"gaaa\" which might be slang or a term from another language. Maybe Spanish? \"Gaaa\" doesn't translate directly, but sometimes words are repeated for emphasis, like \"¡Qué gordo, gordo!\" But that's a stretch.\n",
      "\n",
      "Wait, maybe it's related to sports? Like in soccer, \"goooal\" is sometimes spelled with extra letters for emphasis. So \"RoboGaaa\" might be a robotic soccer team or something. The Robocup is a well-known robotics competition, but I'm not sure if that's it.\n",
      "\n",
      "Alternatively, could it be a project or initiative from a university? Maybe a research group? Let me think of possible acronyms. If I split it as ROBO-GAAA, then GAAA could stand for something. Let's see: GAAA... maybe \"Gaming and Automation for Advanced Applications\"? That seems forced. \n",
      "\n",
      "Alternatively, maybe it's a typo for ROBOGAA or another name. Let me check if I can find any references. Since I can't access external info, I have to rely on existing knowledge. Wait, in the realm of robotics, sometimes companies use catchy names. Maybe it's a specific robot model? Or perhaps it's a meme or slang term in a niche community.\n",
      "\n",
      "Alternatively, ROBOGAAA could be related to the RoboCup, an international festival for students and researchers in robotics and AI. But I don't recall RoboGAAA specifically. Alternatively, maybe it's an AI assistant like ROBO, but with a different name. \n",
      "\n",
      "Another thought: In some contexts, \"gaaa\" might be a misspelling of \"gaga,\" which is associated with Lady Gaga, but that doesn't make sense here. Alternatively, it could be a misspelling of \"gaa\" which is a term in statistics, like Goals Against Average, but again, not sure.\n",
      "\n",
      "Wait, maybe it's a project on GitHub or another platform? If it's a GitHub repo, perhaps it's an open-source robotics project. Alternatively, maybe it's a new app or service. Hmm.\n",
      "\n",
      "Alternatively, could it be related to RoboFont, a software for type design, but that's a stretch. Maybe a typo for \"RoboGuard\" or something else. \n",
      "\n",
      "Alternatively, maybe it's a misspelling of \"RoboGPT,\" but that's not a known project. Alternatively, ROBOGAAA could be an acronym itself. Let me try expanding it. R-O-B-O-G-A-A-A. Maybe each letter stands for something. R for Robotics, O for something else... but it's challenging. Alternatively, ROBOGAAA might be a term from a specific field I'm not familiar with. \n",
      "\n",
      "Alternatively, thinking of gaming, maybe a mod or a cheat code? Like in some games, you type in codes to activate something. Not sure.\n",
      "\n",
      "Alternatively, maybe it's a brand or product name. A quick mental scan of robotics companies: Boston Dynamics makes robots like Spot, but not RoboGAAA. \n",
      "\n",
      "Wait, perhaps it's a misspelling of \"RoboGaaS,\" where GaaS stands for \"Game as a Service\" or something, but the extra \"a\" makes it GAAA. Not sure.\n",
      "\n",
      "Alternatively, ROBOGAAA could be a play on \"RoboGuardian\" or something similar. \n",
      "\n",
      "Alternatively, maybe it's from a specific community or subculture. For example, in the anime or manga fandom, sometimes terms are coined. But I can't recall any specific reference.\n",
      "\n",
      "Alternatively, thinking of the tech industry, maybe it's a startup that's not very well-known yet. Or perhaps it's a coding challenge or competition. \n",
      "\n",
      "Alternatively, maybe it's a term used in a specific technical context, like in robotics competitions. Maybe it's a team name? Like \"Team ROBOGAAA\" in a competition. \n",
      "\n",
      "Alternatively, the user might have made a typo. Maybe they meant to ask about ROBOCUP, the robotic football (soccer) competition? Or maybe \"RoboGAA\" is a typo for \"RoboGAA,\" but that's still unclear. \n",
      "\n",
      "Alternatively, considering the triple \"A\" maybe it's emphasizing something, like \"ROBOGAAA\" as a more intense or advanced version of a robot. \n",
      "\n",
      "Alternatively, maybe it's a reference to the game \"Robo Rally,\" but that's a board game, not sure. \n",
      "\n",
      "Hmm, since I can't think of a direct hit, maybe I should consider that ROBOGAAA isn't a widely recognized term. Perhaps it's a lesser-known project, a proprietary system, or a term from a particular context. Alternatively, maybe it's a misspelling of another term. \n",
      "\n",
      "Alternatively, ROBOGAAA could be a misspelling of \"ROBOGATE,\" but that's more of a scandal term. Hmm. \n",
      "\n",
      "Alternatively, maybe it's a typo for \"ROBOGA,\" which might stand for something else. \n",
      "\n",
      "Wait, maybe it's related to the GAN (Generative Adversarial Network) in AI, but that's just a stretch. \n",
      "\n",
      "Alternatively, looking for possible domain names, maybe there's a website called robo-gaaa.com, but I can't check. \n",
      "\n",
      "Alternatively, maybe it's a slang term. For example, in gaming, sometimes terms like \"giga\" or \"mega\" are used for emphasis. So \"RoboGiga\" would mean a super robot, but with three A's? Maybe for \"Advanced,\" so \"RoboGAAA\" as \"Robotic Advanced Automation Application\" or something. \n",
      "\n",
      "Alternatively, the triple A could stand for something like \"AI, Automation, Agility, Adaptability,\" but that's speculative. \n",
      "\n",
      "Alternatively, maybe it's a misspelling of \"RoboGAA,\" where GAA could be an acronym for something. For instance, if GAA is \"Global Automation Alliance,\" but I'm not sure. \n",
      "\n",
      "Alternatively, maybe it's a typo for \"RoboGPA,\" but that's a stretch. \n",
      "\n",
      "Alternatively, thinking of the letters: G-A-A-A, maybe in Spanish, \"gaaa\" could be an exclamation, like \"¡Gaaa!\" as an expression, but combining that with Robo... Maybe a robot that makes a sound like \"Gaaa,\" like a robot's voice? \n",
      "\n",
      "Alternatively, in some contexts, \"gaaa\" could be \"gaga\" with extra A's, but again, not sure. \n",
      "\n",
      "Alternatively, maybe it's part of a video game or a character name. For example, in a game, a robot named RoboGaaa. \n",
      "\n",
      "Alternatively, I might have to consider that \"ROBOGAAA\" is a less common term or a specific project. Since I can't think of a common reference, perhaps the user is referring to a lesser-known community project, a specific app, or an internal project name at a company. \n",
      "\n",
      "Alternatively, maybe it's a play on words with \"Robo\" and \"Goa\" (a place) but that's not helpful.\n",
      "\n",
      "Alternatively, maybe it's part of a song, movie, or book. But again, not sure.\n",
      "\n",
      "Alternatively, perhaps it's a misspelling of \"RoboGuard\" or \"RoboGuardian,\" but with an extra A's.\n",
      "\n",
      "Alternatively, maybe it's an acronym for a specific company or service. Let me try expanding the acronym again. R-O-B-O-G-A-A-A. Let's see:\n",
      "\n",
      "- R: Robotics\n",
      "- O: Open-source\n",
      "- B: ... Hmm, maybe not.\n",
      "\n",
      "Alternatively, maybe \"GAAA\" is a different acronym. Let's consider:\n",
      "\n",
      "G - General\n",
      "A - Automation\n",
      "A - Artificial\n",
      "A - Assistance, but that seems off.\n",
      "\n",
      "Alternatively, \"GAAA\" could refer to something in a technical field. Maybe in finance or another industry? Like ROBO in finance is Robo-advisors. But ROBOGAAA? Not sure.\n",
      "\n",
      "Alternatively, considering \"ROBO-GAAA\" as two parts, ROBO (robot) and GAAA. If GAAA is a conference or event? Like a robotics conference acronym?\n",
      "\n",
      "Alternatively, maybe it's a typo for \"RoboGAA,\" where GAA is a sports statistic (Goals Against Average in hockey), but not relevant here.\n",
      "\n",
      "Alternatively, maybe it's related to the gaming industry. For example, in the game \"RoboGAAA\" could be a character or a level.\n",
      "\n",
      "Alternatively, perhaps it's a misspelling of \"RoboGaga,\" referencing Lady Gaga, but that's a stretch.\n",
      "\n",
      "Alternatively, maybe \"ROBOGAAA\" is part of a technical term, like in engineering or software. Maybe a specific protocol or standard?\n",
      "\n",
      "Alternatively, considering the triple A, which are vowels, maybe it's an acronym where each A stands for something. Like A for Automation, A for Adaptability, A for something else. But without more context, it's hard to say.\n",
      "\n",
      "Alternatively, maybe it's a brand name for a consumer product, like a robot vacuum or something, but I don't recall such a product.\n",
      "\n",
      "Alternatively, the user might be referring to the term in a specific context that's not widely known. Maybe an internal project name within a company, or a term from a specific online community. \n",
      "\n",
      "Alternatively, perhaps it's a typo and the user meant \"RoboGaa,\" but even then, I can't think of it.\n",
      "\n",
      "Hmm. Since I can't recall any well-known references, it's possible that ROBOGAAA is a term from a specific niche, a lesser-known initiative, or even a fictional concept. Alternatively, it could be a misspelling or a made-up term by the user. \n",
      "\n",
      "Alternatively, maybe it's related to the GAN (Generative Adversarial Network) in machine learning, but with some play on words. \n",
      "\n",
      "Alternatively, if I think of \"ROBOGAAA\" as \"ROBO + GAAA,\" where GAAA is an acronym for something like \"Global Autonomous Agent Alliance\"? Not sure.\n",
      "\n",
      "Wait, another angle: sometimes companies use alliteration or repeated letters for branding. Maybe \"ROBOGAAA\" is a brand name designed to be catchy.\n",
      "\n",
      "Alternatively, perhaps it's related to the Robo- prefix, which is common in robotics, and \"GAAA\" could be a specific project codename. \n",
      "\n",
      "Alternatively, maybe it's part of a technical specification in robotics, but I can't recall.\n",
      "\n",
      "Alternatively, the user might be referring to a specific incident or event involving a robot with that name, but without more context, it's hard to tell.\n",
      "\n",
      "Alternatively, maybe it's a typo for \"RoboGAA,\" where GAA is a company or acronym. \n",
      "\n",
      "Alternatively, maybe it's \"RoboGAAA\" as in \"Robotic Automation as a Service,\" but the acronym would usually be RAAS. So maybe not.\n",
      "\n",
      "Alternatively, since the user is asking, perhaps they encountered it in a specific context, like a video, article, or online post, but without more info, I can't pinpoint.\n",
      "\n",
      "Alternatively, maybe it's a misspelling of \"RoboGAIA\" or something else. \n",
      "\n",
      "Alternatively, maybe it's related to the Go programming language? Like RoboGaaa as a Go-based robotics framework? Not sure.\n",
      "\n",
      "Alternatively, perhaps it's a typo for \"RoboGear\" or similar.\n",
      "\n",
      "Alternatively, considering the triple A, maybe it's emphasizing the \"AAA\" part, which in gaming refers to triple-A titles, meaning top-tier. So \"RoboGAAA\" might imply a top-tier robotic system? \n",
      "\n",
      "Alternatively, the triple A could be a play on \"AAA batteries,\" so a robot powered by AAA batteries? Unlikely, but possible in a fun context.\n",
      "\n",
      "Alternatively, maybe it's a term used in a specific research paper or an emerging technology. Without access to external info, tough to confirm.\n",
      "\n",
      "Alternatively, maybe it's part of a meme or internet slang. Searching my memory for recent memes... Not that I can recall.\n",
      "\n",
      "Alternatively, perhaps \"ROBOGAAA\" is a misspelling of \"RoboGage,\" but that's a stretch.\n",
      "\n",
      "Alternatively, maybe it's a misspelling of \"RoboGaga,\" referencing Lady Gaga again, but not likely related to robotics.\n",
      "\n",
      "Hmm, I'm stuck. Maybe I should consider that the user might have a typo, and the correct term is something else, like \"ROBOGAA\" or \"ROBOG,\" but without more info, it's hard.\n",
      "\n",
      "Alternatively, maybe it's a term from a non-English language. For example, in Spanish, \"gaaa\" could be a sound, but combined with Robo, maybe a robotic animal or something.\n",
      "\n",
      "Alternatively, maybe the user is referring to the \"GAAA\" as in \"Gigabyte Accelerated AI Assistant,\" but that's just a guess.\n",
      "\n",
      "Alternatively, maybe the user is thinking of a specific hashtag or social media trend, like #RoboGAAA, but I don't recall any such trend.\n",
      "\n",
      "Alternatively, since the user is asking, perhaps it's a new term that hasn't gained much traction yet, or it's a term from a very specific community or project.\n",
      "\n",
      "Alternatively, maybe it's a typo for \"RoboGAAA\" referring to something like \"Robotic Generalized Autonomous Agent Architecture\" or similar, but I'm just making that up.\n",
      "\n",
      "Alternatively, considering \"GOAAA\" could be an acronym for a government agency or a research group, but I can't think of any.\n",
      "\n",
      "Alternatively, maybe it's part of a video game, like a character or mission. For example, in a game like \"RoboGAAA\" could be a boss or a level. \n",
      "\n",
      "Alternatively, maybe it's a misspelling of \"RoboGall\" or another term.\n",
      "\n",
      "Alternatively, maybe it's a term from a book or a movie. For instance, in a sci-fi movie, there's a robot named ROBOGAAA, but I can't think of any.\n",
      "\n",
      "Hmm. Considering all possibilities, perhaps the safest answer is to state that I'm not sure, and maybe the user can provide more context. However, since I have to provide an answer, maybe I should explain possible angles and suggest it might be a niche term or a typo.\n",
      "\n",
      "Alternatively, maybe it's related to the acronym for a specific robotics kit or software. For example, a robotics platform called ROBOGAAA, where GAAA represents components like Guidance, Automation, etc. \n",
      "\n",
      "Alternatively, maybe it's a type of robot used in a specific industry, like manufacturing. \n",
      "\n",
      "Alternatively, perhaps it's a term from a specific university's research. \n",
      "\n",
      "Alternatively, maybe it's part of a newer tech, like a robotic assistant with a name that emphasizes efficiency or speed, with the multiple A's for emphasis.\n",
      "\n",
      "Alternatively, maybe the user means \"RoboGAA\" which is a typo, and the actual term is known in a certain field.\n",
      "\n",
      "Since I can't find an exact match, the best approach is to inform the user that I'm not familiar with the term and ask for more context. But since I need to answer as the assistant, perhaps I should explain possible angles and note that it might be a typo or niche term.\n",
      "\n",
      "Wait, another angle: sometimes \"ROBO\" is a prefix for robot, so maybe \"ROBOGAAA\" is part of a technical specification or a product name. For example, a robotic system with GAAA being a specific module. \n",
      "\n",
      "Alternatively, maybe it's related to the acronym for \"Global Autonomy Application Architecture\" or something similar.\n",
      "\n",
      "Alternatively, perhaps the user is referring to a mistake, like ROBO + GAAA where GAAA is a typo for \"GAIA\" (Global Artificial Intelligence Alliance) but with an extra A.\n",
      "\n",
      "Alternatively, maybe it's part of a specific framework or software package. For instance, a robotic framework with the name ROBOGAAA.\n",
      "\n",
      "Alternatively, maybe it's a misspelling of \"RoboGAA\" where GAA is a company code.\n",
      "\n",
      "Alternatively, considering the triple A, it might be a branding name with alliteration for marketing, like \"GAAA\" as part of a company slogan.\n",
      "\n",
      "Alternatively, maybe it's a play on \"RoboGaga\" which is a mix of Robo and Gaga (as in Lady Gaga), but without context, it's hard to see the connection.\n",
      "\n",
      "Alternatively, maybe it's part of a specific event or conference, like ROBOGAAA 2023, but I can't recall such an event.\n",
      "\n",
      "Hmm, since I can't think of a concrete example, the most accurate answer is that ROBOGAAA isn't a widely recognized term, and it might be a typo, a niche project, or a term from a specific context. The user might have encountered it in a particular setting, so suggesting possible angles and asking for more context would be helpful, but since I have to answer, I can present possible interpretations.\n",
      "\n",
      "Alternatively, maybe the user is referring to the \"RoboGAA\" which is an acronym for something else, like Robotic Guidance and Automation Assistance Alliance, but that's conjecture.\n",
      "\n",
      "Alternatively, since the user capitalized all letters, maybe it's an acronym where each letter stands for something. Let me try expanding it:\n",
      "\n",
      "R - Robotics\n",
      "O - \n",
      "B - \n",
      "O -\n",
      "G - \n",
      "A - \n",
      "A - \n",
      "A - \n",
      "\n",
      "Not sure. Alternatively, maybe it's a misspelling of \"RoboGAA\" which could stand for something like Robotic Guidance, Automation, and Analytics. But without more letters, it's hard.\n",
      "\n",
      "Alternatively, maybe the user meant to write \"RoboGAA\" where GAA is short for \"Global Automation Alliance\" or \"General Automation and Application.\"\n",
      "\n",
      "Alternatively, given that the user might have a typo, perhaps they meant \"ROBOGAA\" and the extra A is a mistake. Alternatively, maybe it's \"RoboGAA\" where GAA is a company's internal project code name.\n",
      "\n",
      "Alternatively, considering the triple A, it could be emphasizing something like \"AAA\" quality in robotics, so \"RoboGAAA\" as a high-quality robotic system.\n",
      "\n",
      "Alternatively, maybe it's a term used in a specific book, movie, or game, which I'm not aware of.\n",
      "\n",
      "Alternatively, maybe it's related to Roomba (iRobot) but with a different name. \n",
      "\n",
      "Alternatively, considering the triple A's might stand for \"Advanced,\" so \"RoboGAAA\" as a more advanced version of a robot.\n",
      "\n",
      "Alternatively, maybe it's part of a technical term in a less common field, like biomedical robotics, where GAAA could stand for something specific there.\n",
      "\n",
      "Alternatively, since I can't find a concrete answer, the answer would be that I'm not aware of a widely recognized term called ROBOGAAA and suggest checking the spelling or providing more context. But since the user is asking, perhaps I can structure the answer to explain possible interpretations and note that it might be a typo or niche term.\n",
      "\n",
      "Alternatively, maybe the user is referring to the \"Googly\" term, but not sure.\n",
      "\n",
      "Alternatively, maybe it's an AI model or framework. For example, \"RoboGAAA\" could be a new AI model focused on robotics, but I haven't heard of such.\n",
      "\n",
      "Alternatively, maybe it's a typo for \"RoboGear\" or another similar term.\n",
      "\n",
      "Alternatively, thinking of \"GOOGLE\", but adding robot, maybe a Google robotics project? But I don't recall such a project called RoboGAAA.\n",
      "\n",
      "Alternatively, perhaps it's part of a specific software package or library in robotics programming.\n",
      "\n",
      "Alternatively, considering the triple A's, maybe it's emphasizing the word \"gaaa\" as in \"gaaa\" being a sound, so a robot that makes that sound, but that's too vague.\n",
      "\n",
      "Alternatively, maybe it's a typo for \"RoboGAA\" where GAA is an acronym for something else, like a specific company or program.\n",
      "\n",
      "Alternatively, maybe it's a term used in a specific language. For example, in French, \"gaaa\" might mean something, but I can't think of it.\n",
      "\n",
      "Alternatively, perhaps it's a misspelling of \"RoboGag\" or something similar.\n",
      "\n",
      "Alternatively, considering that the user might have encountered it in a different context, like a video game, book, or article where it's a project name.\n",
      "\n",
      "Alternatively, maybe it's a term used in a specific community, such as a Discord server or online group, where participants use that term.\n",
      "\n",
      "Alternatively, maybe it's part of a joke or meme, where \"RoboGAAA\" is a humorous term for a robot that's glitchy or has a funny name.\n",
      "\n",
      "Alternatively, maybe it's a typo for \"RoboGAIA,\" combining GAIA (Global Atmospheric Information and Analysis) with robotics, but that's a stretch.\n",
      "\n",
      "Alternatively, considering that \"GAAA\" could be \"Genetic Algorithm for Autonomous Agents\" or something, making ROBOGAAA a system using that algorithm.\n",
      "\n",
      "Alternatively, maybe it's a term from a specific research paper or white paper that uses ROBOGAAA in a specific context.\n",
      "\n",
      "Alternatively, maybe the user is referring to a specific product, like a robotic vacuum or helper device named ROBOGAAA by some company, but I'm not familiar with that.\n",
      "\n",
      "Alternatively, maybe it's related to the acronym \"GAAA\" in a different context, like a sports team or something unrelated to robotics, but combined with Robo.\n",
      "\n",
      "Alternatively, maybe \"ROBOGAAA\" is a misspelling of \"RoboGAA\" and the user can clarify.\n",
      "\n",
      "Alternatively, given that I can't recall any standard reference, the most honest approach is to state that I don't recognize the term and suggest possible interpretations, advising the user to check the spelling or provide more context. \n",
      "\n",
      "Alternatively, maybe it's a term from the game \"RoboGaaa\" where players control robots, but I'm not sure.\n",
      "\n",
      "Alternatively, \"ROBOGAAA\" could be an acronym for a specific robotic system or protocol, but without more details, it's hard to say.\n",
      "\n",
      "Given all that, I think the best approach is to inform the user that I'm not aware of a widely recognized term called ROBOGAAA and mention possible interpretations based on common acronym expansions or possible typos, while suggesting they check the spelling or provide additional information.\n",
      "</think>\n",
      "\n",
      "The term \"ROBOGAAA\" does not correspond to a widely recognized or established term in mainstream technology, robotics, or popular culture. Here are some possible interpretations and considerations:\n",
      "\n",
      "### Possible Meanings or Origins:\n",
      "1. **Misspelling or Typo**:  \n",
      "   - It might be a miswritten term. Common alternatives could include **RoboGAA**, **RoboGA**, or **RoboGiga**, each of which could relate to robotics or AI in niche contexts.  \n",
      "   - The trailing \"GAAA\" might be an attempt to emphasize something (e.g., \"RoboGAAA\" as a playful name for a high-performance robot).\n",
      "\n",
      "2. **Acronym**:  \n",
      "   - A speculative acronym might involve parts like:  \n",
      "     - **R**obot **O**utfit or **O**pen Source, **G**uidance, **A**utomation, **A**pplication, **A**dvanced.  \n",
      "     - However, this is purely conjecture without concrete evidence.\n",
      "\n",
      "3. **Niche Project or Startup**:  \n",
      "   - It could refer to a lesser-known project, company, or initiative in robotics/AI. For example:  \n",
      "     - A robotics startup, a research group's project, or a proprietary automation tool.  \n",
      "     - A community-driven or open-source platform (e.g., a GitHub project or workshop).\n",
      "\n",
      "4. **Gaming or Media Reference**:  \n",
      "   - A character, game, or virtual assistant in a game or media (e.g., a robotic character named \"RoboGaaa\" in a game like *RoboRally* or a sci-fi story).  \n",
      "   - A meme, slang, or inside joke within a specific online community.\n",
      "\n",
      "5. **Technical/Jargon Term**:  \n",
      "   - A specialized term in robotics, engineering, or AI research, such as a specific algorithm, protocol, or hardware component.  \n",
      "   - Could relate to automation, like \"Robotic Generalized Autonomous Application Architecture.\"\n",
      "\n",
      "6. **Cultural Reference**:  \n",
      "   - A stylized name combining \"Robo\" (robot) with \"Gaaa\" (e.g., sound effects, like a robot's vocalization).\n",
      "\n",
      "### Suggestions for the User:\n",
      "- **Check Spelling**: Confirm if the term was intended as \"RoboGAA,\" \"RoboGaga,\" or another variation.  \n",
      "- **Context Clues**: If encountered in a specific article, game, or community, more context would help clarify its meaning.  \n",
      "- **Search Platforms**: Check platforms like GitHub, Reddit, or technical forums for niche references.  \n",
      "\n",
      "### Conclusion:\n",
      "Without additional context, **ROBOGAAA** appears to be either a misspelling, a niche term, or a brand/project name not widely recognized. If you have more details about where you encountered the term, that could help narrow down its meaning!\n"
     ]
    }
   ],
   "source": [
    "#Building model using groq\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "#Creating the model \n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "\n",
    "#Invoking the model\n",
    "result=model.invoke(\"What is ROBOGAAA?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Enginner. Please provide answer to the below question '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#Defining a prompt \n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI Enginner. Please provide answer to the below question \"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the ChatGorq library \n",
    "from langchain_groq import ChatGroq\n",
    "#defining the model\n",
    "model = ChatGroq(model=\"gemma2-9b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Enginner. Please provide answer to the below question '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000020196610910>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002019663F8D0>, model_name='qwen-qwq-32b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Chaining - Combine Prompt to LLM \n",
    "chain = prompt | model \n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"\\n<think>\\nOkay, the user is asking about LangSmith. Let me start by recalling what I know about it. LangSmith is related to LangChain, right? I think LangChain is a framework for building applications with language models. So maybe LangSmith is a tool that works with LangChain?\\n\\nWait, I should check the exact definition. From what I remember, LangSmith is a tool for evaluating and tracking LLM (Large Language Model) applications. It's used to monitor and improve the performance of these models. But I need to be precise here. The user might be looking for its purpose, features, and how it integrates with other tools.\\n\\nI should also mention that LangSmith is part of the LangChain ecosystem, created by LangChain, Inc. It probably helps developers track different aspects of their applications, like the inputs, outputs, and performance metrics. Maybe it includes features like logging, visualization, and analysis tools?\\n\\nI should also think about use cases. For example, if someone is building a chatbot using LangChain, they might use LangSmith to log interactions and see how the model is performing over time. That way, they can identify issues or areas for improvement.\\n\\nWait, is there anything about how it's different from just using standard logging tools? Maybe LangSmith is more specialized for LLMs, providing specific metrics and dashboards tailored to NLP applications. It might handle things like token counts, response times, and even qualitative analysis, like human evaluations.\\n\\nAlso, I should check if there's an open-source version or if it's a commercial product. LangChain itself is open-source, so maybe LangSmith is too, or perhaps it has both free and paid tiers. The user might want to know about accessibility and integration points.\\n\\nI should structure the answer to first define LangSmith, then explain its purpose, key features, and how it integrates with LangChain. Maybe mention some specific features like lineage tracking, visualization, and analysis tools. Also, clarify that it's part of the broader LangChain ecosystem designed for developers working with LLMs.\\n\\nHmm, did I miss anything? Maybe examples of typical workflows where LangSmith would be useful. Like A/B testing different models, monitoring drift in data, or tracking customer interactions over time. Also, mentioning that it helps in debugging and optimizing the application's performance.\\n\\nI should make sure to present this information clearly without getting too technical, but still detailed enough for someone who's familiar with LLM applications. Avoid jargon where possible, but use the correct terms when necessary. Also, ensure that the answer addresses the core question: What is LangSmith?\\n</think>\\n\\n**LangSmith** is a comprehensive tool designed to evaluate, monitor, and improve the performance of applications built with **LangChain**, a framework for developing large language model (LLM) applications. It serves as a critical component of the LangChain ecosystem, providing developers with tools to track, analyze, and optimize their LLM-based workflows. Here's a detailed breakdown:\\n\\n---\\n\\n### **Key Features of LangSmith**:\\n1. **Performance Tracking**:\\n   - **Lineage Tracking**: Logs the entire workflow of an LLM application, including inputs, model responses, and intermediate steps. This helps trace how data flows through the system.\\n   - **Metrics & Monitoring**: Tracks metrics like response time, token usage, and error rates to identify bottlenecks or inefficiencies.\\n\\n2. **Evaluation & Debugging**:\\n   - **Human Evaluation**: Allows users to manually review and score model outputs to assess accuracy and relevance.\\n   - **Automated Analysis**: Identifies patterns in errors, drift in input/output distributions, or unexpected behavior.\\n   - **Debugging Tools**: Highlights where failures occur in a chain (e.g., which step in a LangChain `Chain` or `Agent` failed).\\n\\n3. **Visualization & Analysis**:\\n   - **Interactive Dashboards**: Provides visual insights into application performance, including histograms, timelines, and comparisons of different runs.\\n   - **Comparison Tools**: Enables A/B testing of different models, parameters, or configurations to determine the best-performing setup.\\n\\n4. **Integration with LangChain**:\\n   - LangSmith is tightly integrated with LangChain's `Chain`, `Agent`, and `Toolkit` APIs. Developers can log runs directly from their LangChain workflows, which then appear in LangSmith's UI for analysis.\\n\\n5. **Optimization**:\\n   - **Cost Management**: Helps track and optimize token usage to reduce costs, especially when working with expensive LLMs like GPT-4.\\n   - **Model Selection**: Assists in choosing the best model (e.g., comparing OpenAI, Anthropic, or custom models) based on performance metrics.\\n\\n---\\n\\n### **Use Cases**:\\n- **Chatbot Monitoring**: Track user interactions, analyze chatbot responses, and identify frequent errors or misinterpretations.\\n- **Content Generation**: Evaluate the quality of outputs (e.g., summaries, code, or creative text) and refine prompts or workflows.\\n- **Research & Iteration**: Compare different LLMs, parameters, or prompt strategies to iterate on a solution.\\n- **Production Systems**: Monitor real-time performance in deployed applications and detect drift or degradation over time.\\n\\n---\\n\\n### **How It Works**:\\n- Developers instrument their LangChain applications to log runs into LangSmith. Each run captures the entire execution path (e.g., user input → LLM prompts → model outputs → final response) and stores it in a database.\\n- The LangSmith UI provides a centralized interface to:\\n  - Search and filter runs.\\n  - Replay or re-execute problematic workflows.\\n  - Annotate outputs for further analysis.\\n  - Generate reports for stakeholders.\\n\\n---\\n\\n### **Why Use LangSmith?**:\\n- **End-to-End Visibility**: Provides transparency into how LLMs are being used and their outputs.\\n- **Efficiency**: Streamlines troubleshooting and optimization of complex workflows.\\n- **Collaboration**: Allows teams to share insights and annotate runs for collaborative improvement.\\n\\n---\\n\\n### **Accessibility**:\\n- LangSmith is part of the **LangChain ecosystem** and is open-source, though there may be paid tiers or enterprise features for advanced use cases. It is designed to be easily integrated with LangChain-based applications.\\n\\n---\\n\\nIn summary, **LangSmith** is an essential tool for developers building LLM applications, enabling them to iteratively improve their models, workflows, and user experiences through robust evaluation and analytics.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 1311, 'prompt_tokens': 36, 'total_tokens': 1347, 'completion_time': 3.032509377, 'prompt_time': 0.004212132, 'queue_time': 0.266993647, 'total_time': 3.036721509}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_28178d7ff6', 'finish_reason': 'stop', 'logprobs': None}, id='run--95a9f6da-0e67-41dd-b849-f50a4f5778e8-0', usage_metadata={'input_tokens': 36, 'output_tokens': 1311, 'total_tokens': 1347})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Invoking the chain \n",
    "chain.invoke({\"input\": \"What is langsmith?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, so the user is asking, \"What is LangSmith?\" Let me start by recalling what I know about LangSmith. I remember that LangSmith is a tool related to LangChain, which is a framework for building applications with language models. But I need to be precise here.\n",
      "\n",
      "First, I should confirm the exact relationship between LangSmith and LangChain. I think LangSmith is part of the LangChain ecosystem. From what I've read before, LangChain provides the building blocks for LLM apps, like chains, agents, memory, etc. LangSmith probably extends that by adding some tools for development and monitoring.\n",
      "\n",
      "Wait, the user might be looking for a detailed explanation. Let me break it down. The official description probably mentions that LangSmith is an observability and development tool. Observability in this context means it helps track and understand the performance and behavior of language models and applications built with LangChain. So, it's not just for building apps but also for monitoring them after deployment.\n",
      "\n",
      "I should mention key features. Maybe things like tracking inputs and outputs, monitoring performance metrics, comparing different models, and iterative testing. Oh right, A/B testing models could be important here. Also, developers can use LangSmith to analyze how their models are performing in real-world scenarios.\n",
      "\n",
      "Another point is that LangSmith integrates with LangChain, so if someone is using LangChain to build an application, they can use LangSmith to track how their chains, agents, or other components are functioning. This helps in debugging and improving the application over time.\n",
      "\n",
      "Wait, I should also note that LangChain is open-source, and so is LangSmith, probably under the same ecosystem. That's important because it means developers can use them without vendor lock-in. The main goal of LangSmith is to provide visibility into the model's behavior, which is crucial when dealing with the unpredictability of LLMs.\n",
      "\n",
      "Hmm, maybe I should structure the answer in sections: definition, key features, integration with LangChain, and use cases. That way it's organized and easy to follow. Let me make sure I don't confuse LangSmith with LangChain itself. LangChain is the framework for building, LangSmith is for observing and improving those builds.\n",
      "\n",
      "Also, the user might not know what observability means in this context. I should explain that in simple terms, like monitoring and understanding the system's internal states through outputs and logs. For LLMs, that means tracking the inputs, outputs, and how the model processes information.\n",
      "\n",
      "Another thing to mention is the A/B testing feature. Developers can test different models or configurations side by side to see which performs better. That's a key part of iterative development. Plus, having a dataset of interactions can help in retraining models or refining the application logic.\n",
      "\n",
      "I should also highlight that LangSmith helps in debugging. Since LLMs can be unpredictable, having logs and metrics allows developers to pinpoint where things go wrong. For example, if a chain is producing incorrect answers, they can trace back the inputs and the model's responses to identify issues.\n",
      "\n",
      "Use cases could include developing chatbots, where you need to track user interactions and model responses over time. Or in a recommendation system, monitoring how the model's suggestions change with different inputs or model updates.\n",
      "\n",
      "Wait, is there anything else? Maybe mention that it's part of the LangChain project by Lango, the company behind it? Or is it open-source independently? I think LangChain and LangSmith are both open-source projects, possibly under the same organization. I should check that, but since I can't browse, I'll go with the common knowledge that they are part of the LangChain ecosystem.\n",
      "\n",
      "So putting it all together, the answer should first define LangSmith as an observability and development tool for LangChain applications. Then list key features like tracking, A/B testing, monitoring, integration with LangChain, and use cases. Make sure to explain why it's useful—because LLMs are complex and their behavior can be unpredictable, so having tools to observe and iterate is essential for effective development and maintenance.\n",
      "</think>\n",
      "\n",
      "**LangSmith** is an **observability and development tool** designed to work alongside the **LangChain framework**. It is part of the LangChain ecosystem, which provides tools and libraries for building applications powered by large language models (LLMs). Here's a detailed breakdown:\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Features of LangSmith**\n",
      "1. **Observability & Monitoring**:\n",
      "   - Tracks and logs interactions between your application and LLMs, including inputs, outputs, and intermediate steps (e.g., prompts, model responses, and chain steps).\n",
      "   - Monitors performance metrics (e.g., response latency, error rates) and helps identify bottlenecks.\n",
      "\n",
      "2. **Iterative Model Development**:\n",
      "   - Enables **A/B testing** of different models, prompts, or chains to compare performance.\n",
      "   - Allows developers to refine model configurations and Chains iteratively based on real-world data.\n",
      "\n",
      "3. **Debugging & Analysis**:\n",
      "   - Provides a dashboard to inspect failed or suboptimal responses, helping to debug issues in real time.\n",
      "   - Analyzes model behavior to uncover patterns, biases, or inconsistencies in outputs.\n",
      "\n",
      "4. **Data Collection & Replay**:\n",
      "   - Stores historical data (e.g., user inputs, model outputs) for auditing, retraining models, or improving Chains.\n",
      "   - Supports replaying past interactions to test updates without re-running live data.\n",
      "\n",
      "5. **Integration with LangChain**:\n",
      "   - Seamlessly integrates with LangChain components (e.g., Chains, Agents, Prompts) to track their execution.\n",
      "   - Works with popular LLMs (e.g., OpenAI, Anthropic, HuggingFace) via LangChain’s built-in support.\n",
      "\n",
      "---\n",
      "\n",
      "### **Core Use Cases**\n",
      "- **LLM Application Monitoring**: Track how your application interacts with LLMs in production.\n",
      "- **Model Iteration**: Test new models or prompt versions against historical data.\n",
      "- **Debugging**: Identify and resolve errors in Chains or prompt engineering.\n",
      "- **Compliance & Auditing**: Maintain logs for compliance, explainability, or user feedback analysis.\n",
      "\n",
      "---\n",
      "\n",
      "### **Why Use LangSmith?**\n",
      "LLMs are inherently unpredictable, and their outputs depend on dynamic inputs and contexts. LangSmith helps developers:\n",
      "- **Gain visibility** into how LLMs behave in real-world scenarios.\n",
      "- **Iterate faster** by quickly testing and refining models/Chains.\n",
      "- **Ensure reliability** by identifying and addressing performance issues.\n",
      "\n",
      "---\n",
      "\n",
      "### **How It Works**\n",
      "- Developers instrument their LangChain-based applications to send execution data to LangSmith.\n",
      "- LangSmith aggregates this data into a UI where developers can:\n",
      "  - Visualize Chains and model interactions.\n",
      "  - Filter and analyze specific interactions.\n",
      "  - Create custom dashboards and alerts.\n",
      "\n",
      "---\n",
      "\n",
      "### **Example Workflow**\n",
      "1. Build a LangChain-powered chatbot for customer service.\n",
      "2. Use LangSmith to log user queries, model responses, and Chain steps.\n",
      "3. Identify a surge in \"unhelpful\" responses and analyze the context where they occurred.\n",
      "4. A/B test a revised prompt or a new LLM variant using historical data.\n",
      "5. Deploy the improved configuration and continue monitoring in production.\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Takeaway**\n",
      "LangSmith is essential for teams building production-grade LLM applications, as it bridges the gap between experimentation and deployment by providing actionable insights into model behavior and application performance. It’s designed to make LLM development more transparent, scalable, and maintainable.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"What is langsmith?\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "Okay, I need to explain LangSmith to the user. Let me start by recalling what I know. LangSmith is part of the LangChain ecosystem, right? It's a tool for managing and evaluating language models. Wait, I think it's an observability and experimentation platform. So, its main purposes are tracking model performance, comparing different models, and maybe monitoring the workflow.\n",
      "\n",
      "Hmm, the user might want to know the key features. Let me list them. There's experiment tracking, which allows users to log and compare different model setups. Then there's the user interface, maybe a dashboard where you can visualize metrics. Oh, and model evaluation is a big part—like measuring accuracy, latency, and other performance indicators. Also, maybe it supports A/B testing? That's important for comparing two models directly.\n",
      "\n",
      "I should mention the integration with LangChain components since they work together. The user might be using LangChain for building applications and wants to track their models. Also, data visualization tools within LangSmith help in understanding how models perform over time. Oh, and reproducibility is key here; LangSmith probably helps in keeping track of experiments so you can reproduce results later.\n",
      "\n",
      "Wait, is there anything about deployment? Maybe not directly, but more about the evaluation phase. Also, the user interface is probably browser-based, allowing teams to collaborate. I should also note that it's open-source, which makes it accessible. Oh, and it might support custom metrics and logging of inputs/outputs for analysis.\n",
      "\n",
      "Let me structure this: start with a definition, then key features like experiment tracking, UI, evaluation, integration, visualization, A/B testing, reproducibility, collaboration, and open-source. Make sure to explain each point clearly without getting too technical. Avoid jargon where possible, but since the user is asking about a specific tool, some technical terms are necessary. Check if there's anything else, like community or support? Maybe not needed unless the user asks for more details. Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "**LangSmith** is a powerful tool developed by **LangChain**, designed to help developers, researchers, and teams **observe, evaluate, and optimize language models** and the workflows built around them. It serves as an **observability and experimentation platform** that integrates seamlessly with LangChain's ecosystem. Here's a detailed breakdown of its purpose, features, and use cases:\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Features of LangSmith**\n",
      "1. **Experiment Tracking**:\n",
      "   - Log and track different experiments (e.g., testing various LLMs, prompt templates, or parameters) to compare their performance.\n",
      "   - Store experiment metadata, inputs, outputs, and metrics for reproducibility.\n",
      "\n",
      "2. **Model Evaluation**:\n",
      "   - Measure and analyze critical metrics like:\n",
      "     - **Accuracy**, **latency**, and **cost** of model responses.\n",
      "     - **Human feedback** (e.g., via surveys or ratings).\n",
      "     - **Bias detection** and **safety checks**.\n",
      "   - Compare models side-by-side using **A/B testing** to identify the best performer for specific tasks.\n",
      "\n",
      "3. **Interactive Dashboard**:\n",
      "   - A user-friendly web interface to visualize:\n",
      "     - Performance trends over time.\n",
      "     - Distributions of metrics (e.g., token usage, response times).\n",
      "     - Failure cases and error analysis.\n",
      "\n",
      "4. **Integration with LangChain**:\n",
      "   - Works natively with LangChain components (e.g., LLMs, Chains, Agents, and Tools) to log data automatically.\n",
      "   - Supports tracking of complex workflows (e.g., multi-step pipelines) built with LangChain.\n",
      "\n",
      "5. **Data Visualization**:\n",
      "   - Generate reports and charts to analyze model behavior, such as:\n",
      "     - Success rates for specific tasks.\n",
      "     - Cost-efficiency comparisons between models.\n",
      "     - Error patterns (e.g., hallucinations, incorrect outputs).\n",
      "\n",
      "6. **Reproducibility & Collaboration**:\n",
      "   - Store and version experiments so teams can reproduce results later.\n",
      "   - Share experiments and dashboards with collaborators for feedback.\n",
      "\n",
      "7. **Custom Metrics**:\n",
      "   - Define and track custom evaluation criteria tailored to your use case (e.g., \"correctness,\" \"creativity,\" or domain-specific metrics).\n",
      "\n",
      "---\n",
      "\n",
      "### **Use Cases**\n",
      "- **Model Selection**: Choose the best LLM (e.g., GPT-4 vs. Claude) for a task based on cost, speed, and accuracy.\n",
      "- **Prompt Optimization**: Test different prompt templates to maximize response quality.\n",
      "- **Debugging**: Identify failures in chains or agents by reviewing logged inputs/outputs.\n",
      "- **A/B Testing**: Compare two workflows (e.g., a chain vs. an agent) and select the better-performing option.\n",
      "- **Cost Management**: Track token usage and costs to optimize budget allocation.\n",
      "\n",
      "---\n",
      "\n",
      "### **How It Works**\n",
      "1. **Setup**: Install LangSmith and link it to your LangChain application.\n",
      "2. **Logging**: Automatically or manually log experiments, inputs, outputs, and metrics.\n",
      "3. **Analysis**: Use the dashboard to visualize data, compare results, and refine workflows.\n",
      "4. **Iteration**: Use insights to tweak models, prompts, or workflows for better performance.\n",
      "\n",
      "---\n",
      "\n",
      "### **Why Use LangSmith?**\n",
      "- **Efficiency**: Save time by systematically tracking experiments instead of manually logging results.\n",
      "- **Transparency**: Gain visibility into how models behave in real-world scenarios.\n",
      "- **Scalability**: Handle large-scale testing without losing track of experiments.\n",
      "- **Collaboration**: Share insights with teams to align on improvements.\n",
      "\n",
      "---\n",
      "\n",
      "### **Getting Started**\n",
      "- **Installation**: Use `pip install langsmith` to get started.\n",
      "- **Integration**: Add minimal code to your LangChain app to log runs (e.g., `from langsmith import Client`).\n",
      "- **Dashboards**: Access the UI via a browser to explore and analyze results.\n",
      "\n",
      "---\n",
      "\n",
      "### **Example Workflow**\n",
      "1. Run an experiment to compare GPT-4 and Llama2 on a QA task.\n",
      "2. Log each model's accuracy, response time, and cost per query.\n",
      "3. Use LangSmith’s dashboard to visualize which model is better for cost-sensitive vs. accuracy-critical scenarios.\n",
      "\n",
      "---\n",
      "\n",
      "LangSmith is particularly useful for teams building production-scale applications with LLMs, as it helps demystify model behavior and streamline iterative improvements. It’s part of the broader LangChain ecosystem, which includes tools like Chains, Agents, and LLM evaluation utilities. \n",
      "\n",
      "For more details, check out the [LangSmith documentation](https://python.langchain.com/docs/expression_language/langsmith).\n"
     ]
    }
   ],
   "source": [
    "##Output Parser \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#Defining Output parser object \n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "#Adding output parser at the end\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "#Invoking the chain \n",
    "response=chain.invoke({\"input\":\"Can you tell me about LangSmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "#Instantiating Json Output Parser\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "#DEfining the prompt (Unique for Json)\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variable=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'LangSmith', 'description': 'LangSmith is an open-source platform for building and evaluating large language models (LLMs).', 'features': ['**Open-source:** All code and models are publicly accessible.', '**Modular design:**  Allows for easy customization and experimentation.', '**Flexible training pipeline:** Supports various training methods and datasets.', '**Model evaluation tools:** Provides metrics and visualizations for assessing LLM performance.', '**Community-driven:** Actively developed and maintained by a community of contributors.'], 'website': 'https://github.com/langsmithai/LangSmith', 'purpose': 'To democratize access to LLM development and research by providing a user-friendly and powerful platform.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Adding output parser at the end\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "#Invoking the chain \n",
    "response=chain.invoke({\"query\":\"Can you tell me about LangSmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source framework for building and deploying language models.', 'key_features': ['Modular design allows for easy customization and extensibility.', 'Supports various model architectures, including Transformer-based models.', 'Provides tools for data preprocessing, training, and evaluation.', 'Offers a user-friendly interface for interacting with models.', 'Designed to be lightweight and efficient, suitable for both research and production environments.'], 'benefits': ['Accelerates the development of custom language models.', 'Reduces the barrier to entry for researchers and developers.', 'Enables experimentation with different model architectures and training techniques.', 'Facilitates the deployment of language models in real-world applications.', 'Promotes collaboration and knowledge sharing within the AI community.'], 'resources': ['Website: https://github.com/facebookresearch/langs', 'Documentation: https://facebookresearch.github.io/langs/']}\n"
     ]
    }
   ],
   "source": [
    "### Assisgnment ---Chatprompttemplate\n",
    "\n",
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Importing the ChatGorq library \n",
    "from langchain_groq import ChatGroq\n",
    "#defining the model\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform for developing and deploying language models.', 'features': ['Web-based interface for model training and evaluation', 'Support for various language models, including GPT and T5', 'Fine-tuning capabilities for customizing models to specific tasks', 'Community-driven development with contributions from researchers and developers', 'Open-source code and data for transparency and collaboration'], 'website': 'https://github.com/langsmithai/langsmith', 'status': 'Active development'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "#Instantiating Json Output Parser\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "#DEfining the prompt (Unique for Json)\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variable=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "#Defining the model \n",
    "#Importing the ChatGorq library \n",
    "from langchain_groq import ChatGroq\n",
    "#defining the model\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "#Adding output parser at the end\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "#Invoking the train \n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform designed to simplify the development and deployment of large language models (LLMs).', 'key_features': ['Modular Design:', 'Streamlined Workflow:', 'Fine-Tuning Capabilities:', 'Model Hub:', 'Open-Source and Customizable:'], 'benefits': ['Reduced Development Time:', 'Simplified Deployment:', 'Improved Model Performance:', 'Community Collaboration:', 'Cost-Effectiveness:'], 'target_audience': ['AI Researchers:', 'Data Scientists:', 'Developers:', 'Anyone interested in working with LLMs'], 'website': 'https://github.com/langsmith-ai/langsmith', 'additional_information': 'Langsmith leverages the power of tools like LangChain and LlamaIndex to provide a comprehensive suite of functionalities for LLM development and deployment.'}\n"
     ]
    }
   ],
   "source": [
    "#Generating JSON Response using ChatPromptTemplate \n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. please provide the answer in Json format\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "#Defining the model \n",
    "#Importing the ChatGorq library \n",
    "from langchain_groq import ChatGroq\n",
    "#defining the model\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "\n",
    "#Define output Parser \n",
    "#Instantiating Json Output Parser\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "\n",
    "#Adding output parser at the end\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "#Invoking the train \n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': [{'info': [{'name': 'Langsmith'}, {'description': 'Langsmith is an open-source framework developed by AI21 Labs that aims to simplify the development and deployment of large language models (LLMs). It provides a modular and scalable architecture that allows users to customize and fine-tune LLMs for specific tasks.'}, {'key_features': [{'feature': 'Modular and Customizable'}, {'feature': 'Easy Deployment'}, {'feature': 'Fine-tuning Capabilities'}, {'feature': 'Open-Source'}]}, {'purpose': [{'point': 'Simplifying LLM development and deployment'}, {'point': 'Enabling customization and fine-tuning for specific tasks'}, {'point': 'Providing a collaborative platform for the LLM community'}]}, {'developer': 'AI21 Labs'}, {'license': 'Open-source'}]}]}\n"
     ]
    }
   ],
   "source": [
    "#Generating XML Response using ChatPromptTemplate \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. please provide the answer in XML format\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "#Defining the model \n",
    "#Importing the ChatGorq library \n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "\n",
    "#Define output Parser \n",
    "#Instantiating Json Output Parser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "\n",
    "#Adding output parser at the end\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "#Invoking the train \n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': [{'answer': '\\n\\nLangsmith is an open-source framework developed by the team at Google DeepMind for building and training large language models (LLMs). \\n\\nHere are some key features of Langsmith:\\n\\n* **Modular Design:**  Langsmith is built with a modular design, allowing users to easily customize and extend its functionality.\\n\\n* **Focus on Efficiency:** It prioritizes efficiency in training and deployment, making it suitable for researchers and developers with limited resources.\\n* **Integration with Existing Tools:** Langsmith seamlessly integrates with popular machine learning libraries and tools like TensorFlow and PyTorch.\\n* **Open-Source and Collaborative:** Being open-source, Langsmith encourages community contributions and collaboration, fostering innovation in the field of LLMs.\\n\\nLangsmith aims to democratize access to LLM development by providing a user-friendly and efficient platform.\\n\\n'}]}\n"
     ]
    }
   ],
   "source": [
    "#Generating XML Response using ChatPromptTemplate  \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are an helpful assistant. Respond in XML please provide the answer in XML format with <output> tags\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "#Defining the model \n",
    "#Importing the ChatGorq library \n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "\n",
    "#Define output Parser \n",
    "#Instantiating Json Output Parser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "\n",
    "#Adding output parser at the end\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "#Invoking the train \n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response>\\n  <output>\\n    Langsmith is an open-source platform developed by Google DeepMind that aims to simplify the process of developing and deploying large language models (LLMs). \\n\\n    Here are some key features of Langsmith:\\n\\n    * **Modular Design:** Langsmith is built with a modular architecture, allowing users to easily customize and extend its functionality.\\n    * **Streamlined Workflow:** It provides a streamlined workflow for training, evaluating, and deploying LLMs, making the process more efficient.\\n    * **Experiment Tracking:** Langsmith includes tools for tracking experiments and comparing different model configurations.\\n    * **Open-Source Community:** Being open-source, Langsmith benefits from a vibrant community of developers who contribute to its development and support.\\n\\n    Langsmith is designed to be accessible to a wider range of users, including researchers, developers, and students, by providing a user-friendly interface and comprehensive documentation.\\n  </output>\\n</response> \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 206, 'prompt_tokens': 53, 'total_tokens': 259, 'completion_time': 0.374545455, 'prompt_time': 0.003531136, 'queue_time': 0.247784995, 'total_time': 0.378076591}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--042be8ee-4bfe-487d-86e5-382869e97246-0' usage_metadata={'input_tokens': 53, 'output_tokens': 206, 'total_tokens': 259}\n"
     ]
    }
   ],
   "source": [
    "#Generating XML Response using ChatPromptTemplate  \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\",\"You are an helpful assistant. Respond in XML format: <response><answer> Your answer here </answer></response> please provide the answer in XML format with <output> tags\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "#Defining the model \n",
    "#Importing the ChatGorq library \n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"gemma2-9b-it\")\n",
    "\n",
    "\n",
    "#Define output Parser \n",
    "#Instantiating Json Output Parser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "\n",
    "#Adding output parser at the end\n",
    "chain = prompt | model \n",
    "\n",
    "#Invoking the train \n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JsonOutputParser().get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'It was two tired.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prompt output with Pydantic \n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "\n",
    "#Build the model \n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "#Define your data structure \n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"Question to set up a joke\")\n",
    "    punchline:str = Field(description=\"Answer to resolve the joke\")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke\"\n",
    "\n",
    "\n",
    "#Setup a parser + inject instruction into prompt template \n",
    "parser=JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "\n",
    "#Defining prompt template \n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query. \\n {format_instructions} \\n {query} \\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "#Chain \n",
    "chain = prompt | model | parser \n",
    "\n",
    "chain.invoke({\"query\":joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why couldn't the bicycle find its way home? Because it lost its bearings!\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prompt output removing  Pydantic \n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field \n",
    "\n",
    "\n",
    "#Build the model \n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "#Define your data structure \n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"Question to set up a joke\")\n",
    "    punchline:str = Field(description=\"Answer to resolve the joke\")\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke\"\n",
    "\n",
    "\n",
    "#Setup a parser + inject instruction into prompt template \n",
    "parser=JsonOutputParser()\n",
    "\n",
    "\n",
    "#Defining prompt template \n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query. \\n {format_instructions} \\n {query} \\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "#Chain \n",
    "chain = prompt | model | parser \n",
    "\n",
    "chain.invoke({\"query\":joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the libraries\n",
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "#Define the datamodel of reference using Pydantic\n",
    "class Joke(BaseModel):\n",
    "    setup:str = Field(description=\"Question to setup a joke\")\n",
    "    punchline:str = Field(description=\"Answer to resolve the joke\")\n",
    "    \n",
    "#Build the datamodel \n",
    "model = ChatOpenAI(temperature=.5)\n",
    "\n",
    "\n",
    "#Define the user query \n",
    "joke_query=\"Tell me a joke \"\n",
    "\n",
    "\n",
    "#Setting up the parser + inject instruction onto Prompt template \n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "\n",
    "#Defining the Prompt Template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\":parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "\n",
    "#Build the chain \n",
    "chain = prompt | model | parser\n",
    "\n",
    "#Invoking hte chain \n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Product_Name': 'Samsung Phone',\n",
       " 'Product_Desc': 'Samsung phones are a line of smartphones manufactured by Samsung Electronics. They are known for their high-quality displays, powerful cameras, and innovative features such as the S Pen stylus and curved edge displays.',\n",
       " 'Product_Price': 'The indicative price of Samsung phones varies depending on the model and specifications, ranging from $200 to over $1000.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build an AI Assistant that can use any LLM\n",
    "#Need to generate two details, name and price in USD\n",
    "#Use of Pydantic \n",
    "\n",
    "\n",
    "#Importing the libraries \n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "#Define the llm model \n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "\n",
    "#Define the data model with desired structure\n",
    "class Product(BaseModel):\n",
    "    Product_Name: str = Field(description=\"Provide the name of the product\")\n",
    "    Product_Desc: str = Field(description=\"Provide the description of the product\")  \n",
    "    Product_Price: str = Field(description=\"Provide the indicative price of the Product in USD\")\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Product)\n",
    "\n",
    "#Define the Prompt \n",
    "prompt =  PromptTemplate(\n",
    "    template=\"Answer the user query. \\n {format_instructions} \\n{query} \\n\", \n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "#Define the chain \n",
    "chain = prompt | model | parser \n",
    "\n",
    "\n",
    "#Invoking the joke \n",
    "chain.invoke({\"query\":\"Explain me about a Samsung Phone\"})\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
